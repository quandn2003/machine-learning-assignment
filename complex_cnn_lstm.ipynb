{"cells":[{"cell_type":"code","execution_count":235,"metadata":{"id":"8TFX7wSAmg9y"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from string import digits\n","from collections import Counter\n","from pyvi import ViTokenizer\n","from gensim.models.word2vec import Word2Vec\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":236,"metadata":{"id":"a7lMy03omg93","scrolled":true},"outputs":[],"source":["data_train = pd.read_csv(\"vlsp_sentiment_train.csv\", sep='\\t')\n","data_train.columns =['Class', 'Data']\n","data_test = pd.read_csv(\"vlsp_sentiment_test.csv\", sep='\\t')\n","data_test.columns =['Class', 'Data']"]},{"cell_type":"code","execution_count":237,"metadata":{"id":"4HR1jAzImg94"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Class</th>\n","      <th>Data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1</td>\n","      <td>Mình đã dùng anywhere thế hệ đầu, quả là đầy t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1</td>\n","      <td>Quan tâm nhất là độ trễ có cao không, dùng thi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1</td>\n","      <td>dag xài con cùi bắp 98k....pin trâu, mỗi tội đ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1</td>\n","      <td>logitech chắc hàng phải tiền triệu trở lên dùn...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1</td>\n","      <td>Đang xài con m175 cùi mía , nhà xài nhiều chuộ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Class                                               Data\n","0     -1  Mình đã dùng anywhere thế hệ đầu, quả là đầy t...\n","1     -1  Quan tâm nhất là độ trễ có cao không, dùng thi...\n","2     -1  dag xài con cùi bắp 98k....pin trâu, mỗi tội đ...\n","3     -1  logitech chắc hàng phải tiền triệu trở lên dùn...\n","4     -1  Đang xài con m175 cùi mía , nhà xài nhiều chuộ..."]},"execution_count":237,"metadata":{},"output_type":"execute_result"}],"source":["data_train.head()"]},{"cell_type":"code","execution_count":238,"metadata":{},"outputs":[],"source":["data_train = data_train.sample(frac=1, random_state=42)"]},{"cell_type":"code","execution_count":239,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Class</th>\n","      <th>Data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4039</th>\n","      <td>0</td>\n","      <td>tuy có sự sáng tạo , nhưng cần phải có phong c...</td>\n","    </tr>\n","    <tr>\n","      <th>3815</th>\n","      <td>0</td>\n","      <td>khoảng 3-4s j đó</td>\n","    </tr>\n","    <tr>\n","      <th>848</th>\n","      <td>-1</td>\n","      <td>Chiều dài 45cm :( bỏ vào túi kiểu gì</td>\n","    </tr>\n","    <tr>\n","      <th>4863</th>\n","      <td>0</td>\n","      <td>không , không nên mua . mua samsung ngon hơn .</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>-1</td>\n","      <td>thế thì quất thôi, chứ con miband 1s của e bên...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Class                                               Data\n","4039      0  tuy có sự sáng tạo , nhưng cần phải có phong c...\n","3815      0                                   khoảng 3-4s j đó\n","848      -1               Chiều dài 45cm :( bỏ vào túi kiểu gì\n","4863      0     không , không nên mua . mua samsung ngon hơn .\n","79       -1  thế thì quất thôi, chứ con miband 1s của e bên..."]},"execution_count":239,"metadata":{},"output_type":"execute_result"}],"source":["data_train.head()"]},{"cell_type":"code","execution_count":240,"metadata":{"id":"jvrbwPfZmg95"},"outputs":[],"source":["labels = data_train.iloc[:, 0].values\n","reviews = data_train.iloc[:, 1].values"]},{"cell_type":"code","execution_count":241,"metadata":{"id":"3HlbVeHimg95"},"outputs":[],"source":["encoded_labels = []\n","\n","for label in labels:\n","    if label == -1:\n","        encoded_labels.append([1,0,0])\n","    elif label == 0:\n","        encoded_labels.append([0,1,0])\n","    else:\n","        encoded_labels.append([0,0,1])\n","\n","encoded_labels = np.array(encoded_labels)"]},{"cell_type":"code","execution_count":242,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 0]\n","[0 1 0]\n","[1 0 0]\n","[0 1 0]\n","[1 0 0]\n"]}],"source":["for i in range(5):\n","    print(encoded_labels[i])"]},{"cell_type":"code","execution_count":243,"metadata":{"id":"Lm4OCwxXmg96"},"outputs":[],"source":["reviews_processed = []\n","unlabeled_processed = []\n","for review in reviews:\n","    review_cool_one = ''.join([char for char in review if char not in digits])\n","    reviews_processed.append(review_cool_one)"]},{"cell_type":"code","execution_count":244,"metadata":{"id":"nW2OZgkgmg97"},"outputs":[],"source":["#Use PyVi for Vietnamese word tokenizer\n","word_reviews = []\n","all_words = []\n","for review in reviews_processed:\n","    review = ViTokenizer.tokenize(review.lower())\n","    word_reviews.append(review.split())\n"]},{"cell_type":"code","execution_count":245,"metadata":{"id":"t-8cJ7z4z2C0"},"outputs":[{"data":{"text/plain":["['tuy',\n"," 'có',\n"," 'sự',\n"," 'sáng_tạo',\n"," ',',\n"," 'nhưng',\n"," 'cần',\n"," 'phải',\n"," 'có',\n"," 'phong_cách',\n"," 'riêng',\n"," ',',\n"," 'đừng',\n"," 'chạy',\n"," 'theo',\n"," 'iphone',\n"," ',',\n"," 'samsung',\n"," 'rất',\n"," 'cố_gắng',\n"," ',',\n"," 'biết',\n"," 'nắm_bắt',\n"," 'nhu_cầu',\n"," 'khách_hàng',\n"," '(',\n"," 's',\n"," 's',\n"," 'edge',\n"," 'người',\n"," 'châu',\n"," 'á',\n"," 'rất',\n"," 'chuộng',\n"," ',',\n"," 'nhưng',\n"," 'ko',\n"," 'thấy',\n"," 'phát_triển',\n"," 'nữa',\n"," ')',\n"," 's',\n"," 'là',\n"," 'sự',\n"," 'hoàn_thiện',\n"," 'của',\n"," 's',\n"," ',',\n"," 'nhưng',\n"," 'sfan',\n"," 'thì',\n"," 'luôn',\n"," 'gato',\n"," ',',\n"," 'vì',\n"," 'các',\n"," 'bạn',\n"," 'ấy',\n"," 'thấy',\n"," 'iphone',\n"," 'quá',\n"," 'đắt',\n"," 'và',\n"," 'các',\n"," 'bạn',\n"," 'ấy',\n"," 'chuẩn_bị',\n"," 'lên_tiếng',\n"," '.']"]},"execution_count":245,"metadata":{},"output_type":"execute_result"}],"source":["word_reviews[0]"]},{"cell_type":"code","execution_count":246,"metadata":{"id":"pTb0MeDRmg98"},"outputs":[],"source":["EMBEDDING_DIM = 400 # how big is each word vector\n","MAX_VOCAB_SIZE = 10000 # how many unique words to use (i.e num rows in embedding vector)\n","MAX_SEQUENCE_LENGTH = 300 # max number of words in a comment to use"]},{"cell_type":"code","execution_count":247,"metadata":{"id":"jW-7mKtWmg9-"},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":248,"metadata":{"id":"-BHpPSLTmg9_"},"outputs":[],"source":["tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=True, char_level=False)\n","tokenizer.fit_on_texts(word_reviews)\n","sequences_train = tokenizer.texts_to_sequences(word_reviews)\n","word_index = tokenizer.word_index\n"]},{"cell_type":"code","execution_count":249,"metadata":{"id":"fX8asUU4MxMK"},"outputs":[],"source":["# word_index[1]"]},{"cell_type":"code","execution_count":250,"metadata":{"id":"LlV3M2dimg9_"},"outputs":[],"source":["data = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n","labels = encoded_labels"]},{"cell_type":"code","execution_count":251,"metadata":{"id":"PTfd3gXdNoU4"},"outputs":[{"data":{"text/plain":["array([[   0,    0,    0, ...,  950, 2022,    1],\n","       [   0,    0,    0, ...,   60,  309,   62],\n","       [   0,    0,    0, ...,  726,  310,   43],\n","       ...,\n","       [   0,    0,    0, ...,   11,  434, 1036],\n","       [   0,    0,    0, ..., 4142,    6,  158],\n","       [   0,    0,    0, ...,   33,   33,    1]])"]},"execution_count":251,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":252,"metadata":{"id":"4dl9VZ3Rmg-A"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X train and X validation tensor: (5100, 300)\n","Shape of label train and validation tensor: (5100, 3)\n"]}],"source":["print('Shape of X train and X validation tensor:',data.shape)\n","print('Shape of label train and validation tensor:', labels.shape)"]},{"cell_type":"code","execution_count":253,"metadata":{"id":"-KKSjJdJmg-A"},"outputs":[],"source":["import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","word_vectors = KeyedVectors.load_word2vec_format('vi-model-CBOW.bin', binary=True)\n","\n","\n","vocabulary_size=min(len(word_index)+1,MAX_VOCAB_SIZE)\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i>=MAX_VOCAB_SIZE:\n","        continue\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n","\n","del(word_vectors)\n","\n","from keras.layers import Embedding\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=True)"]},{"cell_type":"code","execution_count":254,"metadata":{},"outputs":[],"source":["from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, MaxPooling2D, Embedding, BatchNormalization, AveragePooling1D, LSTM, Bidirectional\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input, Dense, Embedding, Dropout,concatenate\n","from tensorflow.keras.layers import Reshape, Flatten\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import regularizers"]},{"cell_type":"code","execution_count":255,"metadata":{"id":"njBANdn5mg-B"},"outputs":[{"name":"stdout","output_type":"stream","text":["<keras.src.engine.functional.Functional object at 0x000002BE38DA7350>\n","Model: \"model_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_10 (InputLayer)       [(None, 300)]             0         \n","                                                                 \n"," embedding_8 (Embedding)     (None, 300, 400)          3167600   \n","                                                                 \n"," dropout_27 (Dropout)        (None, 300, 400)          0         \n","                                                                 \n"," conv1d_9 (Conv1D)           (None, 297, 64)           102464    \n","                                                                 \n"," max_pooling1d_9 (MaxPoolin  (None, 296, 64)           0         \n"," g1D)                                                            \n","                                                                 \n"," dropout_28 (Dropout)        (None, 296, 64)           0         \n","                                                                 \n"," bidirectional_9 (Bidirecti  (None, 128)               66048     \n"," onal)                                                           \n","                                                                 \n"," dropout_29 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 3336499 (12.73 MB)\n","Trainable params: 3336499 (12.73 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["sequence_length = data.shape[1]\n","filter_sizes = [3,4,5]\n","num_filters = 100\n","drop = 0.5\n","\n","inputs = Input(shape=(sequence_length,))\n","embedding = embedding_layer(inputs)\n","dropout1 = Dropout(drop)(embedding)\n","conv1 = Conv1D(64, 3, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n","maxpool1 = MaxPooling1D(2, strides=1)(conv1)\n","conv2 = Conv1D(64, 4, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n","maxpool2 = MaxPooling1D(2, strides=1)(conv2)\n","conv3 = Conv1D(64, 5, activation='relu', kernel_regularizer=regularizers.l2(0.01))(dropout1)\n","maxpool3 = MaxPooling1D(2, strides=1)(conv3)\n","\n","concatenated_tensor = concatenate([maxpool1, maxpool2, maxpool3], axis=1)\n","\n","dropout2 = Dropout(drop)(concatenated_tensor)\n","\n","lstm = Bidirectional(LSTM(64))(dropout2)\n","dropout3 = Dropout(drop)(lstm)\n","output = Dense(units=3, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(dropout3)\n","\n","model = Model(inputs, output)\n","print(model)\n","\n","adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","model.summary()\n","\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=10, verbose=1)"]},{"cell_type":"code","execution_count":256,"metadata":{"colab":{"background_save":true},"id":"Jn0dBlzjmg-D"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","16/16 [==============================] - 25s 1s/step - loss: 2.1959 - accuracy: 0.3490 - val_loss: 2.0172 - val_accuracy: 0.4176\n","Epoch 2/50\n","16/16 [==============================] - 19s 1s/step - loss: 1.9338 - accuracy: 0.3824 - val_loss: 1.7875 - val_accuracy: 0.4392\n","Epoch 3/50\n","16/16 [==============================] - 20s 1s/step - loss: 1.6967 - accuracy: 0.4135 - val_loss: 1.5596 - val_accuracy: 0.4843\n","Epoch 4/50\n","16/16 [==============================] - 20s 1s/step - loss: 1.5060 - accuracy: 0.4581 - val_loss: 1.4030 - val_accuracy: 0.5108\n","Epoch 5/50\n","16/16 [==============================] - 20s 1s/step - loss: 1.3504 - accuracy: 0.5132 - val_loss: 1.2438 - val_accuracy: 0.5696\n","Epoch 6/50\n","16/16 [==============================] - 18s 1s/step - loss: 1.2346 - accuracy: 0.5500 - val_loss: 1.1699 - val_accuracy: 0.5863\n","Epoch 7/50\n","16/16 [==============================] - 20s 1s/step - loss: 1.1580 - accuracy: 0.5799 - val_loss: 1.0965 - val_accuracy: 0.6039\n","Epoch 8/50\n","16/16 [==============================] - 20s 1s/step - loss: 1.1034 - accuracy: 0.5963 - val_loss: 1.0730 - val_accuracy: 0.6059\n","Epoch 9/50\n","16/16 [==============================] - 19s 1s/step - loss: 1.0515 - accuracy: 0.6176 - val_loss: 1.0483 - val_accuracy: 0.6039\n","Epoch 10/50\n","16/16 [==============================] - 20s 1s/step - loss: 1.0079 - accuracy: 0.6566 - val_loss: 1.0253 - val_accuracy: 0.6304\n","Epoch 11/50\n","16/16 [==============================] - 20s 1s/step - loss: 0.9796 - accuracy: 0.6588 - val_loss: 1.0293 - val_accuracy: 0.6255\n","Epoch 12/50\n","16/16 [==============================] - 18s 1s/step - loss: 0.9449 - accuracy: 0.6735 - val_loss: 1.0334 - val_accuracy: 0.6382\n","Epoch 13/50\n","16/16 [==============================] - 19s 1s/step - loss: 0.9131 - accuracy: 0.6983 - val_loss: 1.0031 - val_accuracy: 0.6441\n","Epoch 14/50\n","16/16 [==============================] - 18s 1s/step - loss: 0.8867 - accuracy: 0.7152 - val_loss: 1.0002 - val_accuracy: 0.6539\n","Epoch 15/50\n","16/16 [==============================] - 17s 1s/step - loss: 0.8544 - accuracy: 0.7304 - val_loss: 0.9831 - val_accuracy: 0.6490\n","Epoch 16/50\n","16/16 [==============================] - 17s 1s/step - loss: 0.8965 - accuracy: 0.7047 - val_loss: 0.9959 - val_accuracy: 0.6539\n","Epoch 17/50\n","16/16 [==============================] - 17s 1s/step - loss: 0.8385 - accuracy: 0.7419 - val_loss: 1.0506 - val_accuracy: 0.6402\n","Epoch 18/50\n","16/16 [==============================] - 16s 1s/step - loss: 0.8250 - accuracy: 0.7404 - val_loss: 1.0073 - val_accuracy: 0.6451\n","Epoch 19/50\n","16/16 [==============================] - 17s 1s/step - loss: 0.7839 - accuracy: 0.7686 - val_loss: 1.0071 - val_accuracy: 0.6676\n","Epoch 20/50\n","16/16 [==============================] - 17s 1s/step - loss: 0.7548 - accuracy: 0.7846 - val_loss: 1.0327 - val_accuracy: 0.6559\n","Epoch 21/50\n","16/16 [==============================] - 18s 1s/step - loss: 0.7435 - accuracy: 0.7985 - val_loss: 1.0069 - val_accuracy: 0.6667\n","Epoch 22/50\n","16/16 [==============================] - 16s 1s/step - loss: 0.7238 - accuracy: 0.8025 - val_loss: 1.0289 - val_accuracy: 0.6667\n","Epoch 23/50\n","16/16 [==============================] - 17s 1s/step - loss: 0.7310 - accuracy: 0.8017 - val_loss: 1.0517 - val_accuracy: 0.6637\n","Epoch 24/50\n","16/16 [==============================] - 18s 1s/step - loss: 0.7390 - accuracy: 0.8047 - val_loss: 1.0540 - val_accuracy: 0.6784\n","Epoch 25/50\n","16/16 [==============================] - 18s 1s/step - loss: 0.7180 - accuracy: 0.8123 - val_loss: 1.1233 - val_accuracy: 0.6441\n","Epoch 25: early stopping\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x2be3bbabed0>"]},"execution_count":256,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint = ModelCheckpoint('complex_cnn_lstm.keras',\n","                             monitor='val_accuracy',\n","                             save_best_only=True, verbose=False, mode='max')\n","callbacks_list = [checkpoint, early_stopping]\n","\n","model.fit(data, labels, validation_split=0.2,\n","          epochs=50 , batch_size=256, callbacks=callbacks_list, shuffle=True)"]},{"cell_type":"code","execution_count":257,"metadata":{"colab":{"background_save":true},"id":"8XoN2UOamg-D"},"outputs":[],"source":["labels_test = data_test.iloc[:, 0].values\n","reviews_test = data_test.iloc[:, 1].values"]},{"cell_type":"code","execution_count":258,"metadata":{"colab":{"background_save":true},"id":"PwiYb3Ohmg-E"},"outputs":[],"source":["encoded_labels_test = []\n","\n","for label_test in labels_test:\n","    if label_test == -1:\n","        encoded_labels_test.append([1,0,0])\n","    elif label_test == 0:\n","        encoded_labels_test.append([0,1,0])\n","    else:\n","        encoded_labels_test.append([0,0,1])\n","\n","encoded_labels_test = np.array(encoded_labels_test)"]},{"cell_type":"code","execution_count":259,"metadata":{"colab":{"background_save":true},"id":"E08tBw9img-E"},"outputs":[],"source":["reviews_processed_test = []\n","unlabeled_processed_test = []\n","for review_test in reviews_test:\n","    review_cool_one = ''.join([char for char in review_test])\n","    reviews_processed_test.append(review_cool_one)"]},{"cell_type":"code","execution_count":260,"metadata":{"colab":{"background_save":true},"id":"OwgI9Xywmg-E"},"outputs":[],"source":["#Use PyVi for Vietnamese word tokenizer\n","word_reviews_test = []\n","all_words = []\n","for review_test in reviews_processed_test:\n","    review_test = ViTokenizer.tokenize(review_test.lower())\n","    word_reviews_test.append(review_test.split())"]},{"cell_type":"code","execution_count":261,"metadata":{"colab":{"background_save":true},"id":"p02GxCh6mg-F"},"outputs":[],"source":["sequences_test = tokenizer.texts_to_sequences(word_reviews_test)\n","data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n","labels_test = encoded_labels_test"]},{"cell_type":"code","execution_count":262,"metadata":{"colab":{"background_save":true},"id":"jAqUMGInmg-F"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X train and X validation tensor: (1050, 300)\n","Shape of label train and validation tensor: (1050, 3)\n"]}],"source":["print('Shape of X train and X validation tensor:',data_test.shape)\n","print('Shape of label train and validation tensor:', labels_test.shape)"]},{"cell_type":"code","execution_count":263,"metadata":{"colab":{"background_save":true},"id":"LKclttiOmg-F"},"outputs":[{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 1s 34ms/step - loss: 1.0808 - accuracy: 0.6743\n"]}],"source":["# model = load_model('best_model.keras')\n","score = model.evaluate(data_test, labels_test)"]},{"cell_type":"code","execution_count":264,"metadata":{"colab":{"background_save":true},"id":"r31_uxxgmg-G"},"outputs":[{"name":"stdout","output_type":"stream","text":["loss: 108.08%\n","accuracy: 67.43%\n"]}],"source":["print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1rFZZf9ECknkLNDv8so_kQNPhqain0RqJ","timestamp":1653989613942}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
